{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to torchcutter Installation pip install torchcutter - Install torchcutter. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 Makefile <- Makefile with commands like `make data`, `make train` or 'make deploy', ... etc \u251c\u2500\u2500 README.md <- The top-level README for developers using this project. \u251c\u2500\u2500 data \u2502 \u251c\u2500\u2500 external <- Data from third party sources. \u2502 \u251c\u2500\u2500 interim <- Intermediate data that has been transformed. \u2502 \u251c\u2500\u2500 processed <- The final, canonical data sets for modeling. \u2502 \u2514\u2500\u2500 raw <- The original, immutable data dump. \u2502 \u251c\u2500\u2500 docs <- torchcutter documentation \u2502 \u251c\u2500\u2500 output <- Trained and serialized models, model predictions, or model summaries \u2502 \u2514\u2500\u2500 figures <- Generated model evaluation figures \u2502 \u2514\u2500\u2500 models <- Saves checkpoints \u2502 \u251c\u2500\u2500 notebooks <- Jupyter notebooks. Naming convention is a number (for ordering), \u2502 the creator's initials, and a short `-` delimited description, e.g. \u2502 `1.0-jqp-initial-data-exploration`. \u2502 \u251c\u2500\u2500 references <- Data dictionaries, manuals, and all other explanatory materials. \u2502 \u251c\u2500\u2500 reports <- Generated analysis as HTML, PDF, LaTeX, etc. \u2502 \u2514\u2500\u2500 figures <- Generated graphics and figures to be used in reporting \u2502 \u251c\u2500\u2500 requirements.txt <- The requirements file for reproducing the analysis environment, e.g. \u2502 generated with `pip freeze > requirements.txt` \u2502 \u251c\u2500\u2500 setup.py <- makes project pip installable (pip install -e .) so src can be imported \u251c\u2500\u2500 src <- Source code for use in this project. \u2502 \u251c\u2500\u2500 __init__.py <- Makes src a Python module \u2502 \u2502 \u2502 \u251c\u2500\u2500 data <- data helpers; classes and functions \u2502 \u2502 \u2514\u2500\u2500 dataset.py <- Custom PyTorch dataset \u2502 \u2502 \u2514\u2500\u2500 get_data.py <- Get data wrapped into dataloader ready to be used to train model \u2502 \u2502 \u2502 \u251c\u2500\u2500 models <- Model architecture to train \u2502 \u2502 \u2514\u2500\u2500 model.py <- Model architecture in PyTorch \u2502 \u2502 \u2502 \u251c\u2500\u2500 tester <- Testing and make inference using the pretrained checkpoints \u2502 \u2502 \u251c\u2500\u2500 base.py <- Abstract class for testing model \u2502 \u2502 \u2514\u2500\u2500 tester.py <- Class implementing routines to make inference with a checkpoint \u2502 \u2502 \u2502 \u251c\u2500\u2500 trainer <- Testing and make inference using the pretrained checkpoints \u2502 \u2502 \u251c\u2500\u2500 base.py <- Abstract class for training model \u2502 \u2502 \u2514\u2500\u2500 tester.py <- Class implementing routines to train the model \u2502 \u2502 \u2502 \u251c\u2500\u2500 utils <- utility classes and function \u2502 \u2502 \u251c\u2500\u2500\u2500 io <- Module for input/output operations \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500 read.py <- Read from disk functions utility, like Read configuration file, ... etc \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500 write.py <- write to disk functions utility, liek write to csv file, ... etc \u2502 \u2514\u2500\u2500 tox.ini <- tox file with settings for running tox; see tox.readthedocs.io","title":"Welcome to torchcutter"},{"location":"#welcome-to-torchcutter","text":"","title":"Welcome to torchcutter"},{"location":"#installation","text":"pip install torchcutter - Install torchcutter. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Installation"},{"location":"#project-layout","text":"\u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 Makefile <- Makefile with commands like `make data`, `make train` or 'make deploy', ... etc \u251c\u2500\u2500 README.md <- The top-level README for developers using this project. \u251c\u2500\u2500 data \u2502 \u251c\u2500\u2500 external <- Data from third party sources. \u2502 \u251c\u2500\u2500 interim <- Intermediate data that has been transformed. \u2502 \u251c\u2500\u2500 processed <- The final, canonical data sets for modeling. \u2502 \u2514\u2500\u2500 raw <- The original, immutable data dump. \u2502 \u251c\u2500\u2500 docs <- torchcutter documentation \u2502 \u251c\u2500\u2500 output <- Trained and serialized models, model predictions, or model summaries \u2502 \u2514\u2500\u2500 figures <- Generated model evaluation figures \u2502 \u2514\u2500\u2500 models <- Saves checkpoints \u2502 \u251c\u2500\u2500 notebooks <- Jupyter notebooks. Naming convention is a number (for ordering), \u2502 the creator's initials, and a short `-` delimited description, e.g. \u2502 `1.0-jqp-initial-data-exploration`. \u2502 \u251c\u2500\u2500 references <- Data dictionaries, manuals, and all other explanatory materials. \u2502 \u251c\u2500\u2500 reports <- Generated analysis as HTML, PDF, LaTeX, etc. \u2502 \u2514\u2500\u2500 figures <- Generated graphics and figures to be used in reporting \u2502 \u251c\u2500\u2500 requirements.txt <- The requirements file for reproducing the analysis environment, e.g. \u2502 generated with `pip freeze > requirements.txt` \u2502 \u251c\u2500\u2500 setup.py <- makes project pip installable (pip install -e .) so src can be imported \u251c\u2500\u2500 src <- Source code for use in this project. \u2502 \u251c\u2500\u2500 __init__.py <- Makes src a Python module \u2502 \u2502 \u2502 \u251c\u2500\u2500 data <- data helpers; classes and functions \u2502 \u2502 \u2514\u2500\u2500 dataset.py <- Custom PyTorch dataset \u2502 \u2502 \u2514\u2500\u2500 get_data.py <- Get data wrapped into dataloader ready to be used to train model \u2502 \u2502 \u2502 \u251c\u2500\u2500 models <- Model architecture to train \u2502 \u2502 \u2514\u2500\u2500 model.py <- Model architecture in PyTorch \u2502 \u2502 \u2502 \u251c\u2500\u2500 tester <- Testing and make inference using the pretrained checkpoints \u2502 \u2502 \u251c\u2500\u2500 base.py <- Abstract class for testing model \u2502 \u2502 \u2514\u2500\u2500 tester.py <- Class implementing routines to make inference with a checkpoint \u2502 \u2502 \u2502 \u251c\u2500\u2500 trainer <- Testing and make inference using the pretrained checkpoints \u2502 \u2502 \u251c\u2500\u2500 base.py <- Abstract class for training model \u2502 \u2502 \u2514\u2500\u2500 tester.py <- Class implementing routines to train the model \u2502 \u2502 \u2502 \u251c\u2500\u2500 utils <- utility classes and function \u2502 \u2502 \u251c\u2500\u2500\u2500 io <- Module for input/output operations \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500 read.py <- Read from disk functions utility, like Read configuration file, ... etc \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500 write.py <- write to disk functions utility, liek write to csv file, ... etc \u2502 \u2514\u2500\u2500 tox.ini <- tox file with settings for running tox; see tox.readthedocs.io","title":"Project layout"}]}
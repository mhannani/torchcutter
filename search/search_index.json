{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to torchcutter Getting started I've created this PyTorch training, evaluation and deployment template for Pytorch enthusiast to better make the aforementioned tasks and focus on quality. requirements to use Torchcutter template Python 3.5+ [Cookiecutter package] >= 1.4.0 (https://github.com/cookiecutter/cookiecutter) Install Cookiecutter Via pip package manager: $ pip install cookiecutter Or via conda: $ conda config --add channels conda-forge $ conda install cookiecutter Create new project based on torchcutter template cookiecutter https://github.com/mhannani/torchcutter Project layout \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 Makefile <- Makefile with commands like `make data`, `make train` or 'make deploy', ... etc \u251c\u2500\u2500 README.md <- The top-level README for developers using this project. \u251c\u2500\u2500 data \u2502 \u251c\u2500\u2500 external <- Data from third party sources. \u2502 \u251c\u2500\u2500 interim <- Intermediate data that has been transformed. \u2502 \u251c\u2500\u2500 processed <- The final, canonical data sets for modeling. \u2502 \u2514\u2500\u2500 raw <- The original, immutable data dump. \u2502 \u251c\u2500\u2500 docs <- torchcutter documentation \u2502 \u251c\u2500\u2500 output <- Trained and serialized models, model predictions, or model summaries \u2502 \u2514\u2500\u2500 figures <- Generated model evaluation figures \u2502 \u2514\u2500\u2500 models <- Saves checkpoints \u2502 \u251c\u2500\u2500 notebooks <- Jupyter notebooks. Naming convention is a number (for ordering), \u2502 the creator's initials, and a short `-` delimited description, e.g. \u2502 `1.0-jqp-initial-data-exploration`. \u2502 \u251c\u2500\u2500 references <- Data dictionaries, manuals, and all other explanatory materials. \u2502 \u251c\u2500\u2500 reports <- Generated analysis as HTML, PDF, LaTeX, etc. \u2502 \u2514\u2500\u2500 figures <- Generated graphics and figures to be used in reporting \u2502 \u251c\u2500\u2500 requirements.txt <- The requirements file for reproducing the analysis environment, e.g. \u2502 generated with `pip freeze > requirements.txt` \u2502 \u251c\u2500\u2500 setup.py <- makes project pip installable (pip install -e .) so src can be imported \u251c\u2500\u2500 src <- Source code for use in this project. \u2502 \u251c\u2500\u2500 __init__.py <- Makes src a Python module \u2502 \u2502 \u2502 \u251c\u2500\u2500 data <- data helpers; classes and functions \u2502 \u2502 \u2514\u2500\u2500 dataset.py <- Custom PyTorch dataset \u2502 \u2502 \u2514\u2500\u2500 get_data.py <- Get data wrapped into dataloader ready to be used to train model \u2502 \u2502 \u2502 \u251c\u2500\u2500 models <- Model architecture to train \u2502 \u2502 \u2514\u2500\u2500 model.py <- Model architecture in PyTorch \u2502 \u2502 \u2502 \u251c\u2500\u2500 tester <- Testing and make inference using the pretrained checkpoints \u2502 \u2502 \u251c\u2500\u2500 base.py <- Abstract class for testing model \u2502 \u2502 \u2514\u2500\u2500 tester.py <- Class implementing routines to make inference with a checkpoint \u2502 \u2502 \u2502 \u251c\u2500\u2500 trainer <- Testing and make inference using the pretrained checkpoints \u2502 \u2502 \u251c\u2500\u2500 base.py <- Abstract class for training model \u2502 \u2502 \u2514\u2500\u2500 tester.py <- Class implementing routines to train the model \u2502 \u2502 \u2502 \u251c\u2500\u2500 utils <- utility classes and function \u2502 \u2502 \u251c\u2500\u2500\u2500 io <- Module for input/output operations \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500 read.py <- Read from disk functions utility, like Read configuration file, ... etc \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500 write.py <- write to disk functions utility, liek write to csv file, ... etc \u2502 \u2514\u2500\u2500 tox.ini <- tox file with settings for running tox; see tox.readthedocs.io","title":"Welcome to torchcutter"},{"location":"#welcome-to-torchcutter","text":"","title":"Welcome to torchcutter"},{"location":"#getting-started","text":"I've created this PyTorch training, evaluation and deployment template for Pytorch enthusiast to better make the aforementioned tasks and focus on quality.","title":"Getting started"},{"location":"#requirements-to-use-torchcutter-template","text":"Python 3.5+ [Cookiecutter package] >= 1.4.0 (https://github.com/cookiecutter/cookiecutter)","title":"requirements to use Torchcutter template"},{"location":"#install-cookiecutter","text":"Via pip package manager: $ pip install cookiecutter Or via conda: $ conda config --add channels conda-forge $ conda install cookiecutter","title":"Install Cookiecutter"},{"location":"#create-new-project-based-on-torchcutter-template","text":"cookiecutter https://github.com/mhannani/torchcutter","title":"Create new project based on torchcutter template"},{"location":"#project-layout","text":"\u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 Makefile <- Makefile with commands like `make data`, `make train` or 'make deploy', ... etc \u251c\u2500\u2500 README.md <- The top-level README for developers using this project. \u251c\u2500\u2500 data \u2502 \u251c\u2500\u2500 external <- Data from third party sources. \u2502 \u251c\u2500\u2500 interim <- Intermediate data that has been transformed. \u2502 \u251c\u2500\u2500 processed <- The final, canonical data sets for modeling. \u2502 \u2514\u2500\u2500 raw <- The original, immutable data dump. \u2502 \u251c\u2500\u2500 docs <- torchcutter documentation \u2502 \u251c\u2500\u2500 output <- Trained and serialized models, model predictions, or model summaries \u2502 \u2514\u2500\u2500 figures <- Generated model evaluation figures \u2502 \u2514\u2500\u2500 models <- Saves checkpoints \u2502 \u251c\u2500\u2500 notebooks <- Jupyter notebooks. Naming convention is a number (for ordering), \u2502 the creator's initials, and a short `-` delimited description, e.g. \u2502 `1.0-jqp-initial-data-exploration`. \u2502 \u251c\u2500\u2500 references <- Data dictionaries, manuals, and all other explanatory materials. \u2502 \u251c\u2500\u2500 reports <- Generated analysis as HTML, PDF, LaTeX, etc. \u2502 \u2514\u2500\u2500 figures <- Generated graphics and figures to be used in reporting \u2502 \u251c\u2500\u2500 requirements.txt <- The requirements file for reproducing the analysis environment, e.g. \u2502 generated with `pip freeze > requirements.txt` \u2502 \u251c\u2500\u2500 setup.py <- makes project pip installable (pip install -e .) so src can be imported \u251c\u2500\u2500 src <- Source code for use in this project. \u2502 \u251c\u2500\u2500 __init__.py <- Makes src a Python module \u2502 \u2502 \u2502 \u251c\u2500\u2500 data <- data helpers; classes and functions \u2502 \u2502 \u2514\u2500\u2500 dataset.py <- Custom PyTorch dataset \u2502 \u2502 \u2514\u2500\u2500 get_data.py <- Get data wrapped into dataloader ready to be used to train model \u2502 \u2502 \u2502 \u251c\u2500\u2500 models <- Model architecture to train \u2502 \u2502 \u2514\u2500\u2500 model.py <- Model architecture in PyTorch \u2502 \u2502 \u2502 \u251c\u2500\u2500 tester <- Testing and make inference using the pretrained checkpoints \u2502 \u2502 \u251c\u2500\u2500 base.py <- Abstract class for testing model \u2502 \u2502 \u2514\u2500\u2500 tester.py <- Class implementing routines to make inference with a checkpoint \u2502 \u2502 \u2502 \u251c\u2500\u2500 trainer <- Testing and make inference using the pretrained checkpoints \u2502 \u2502 \u251c\u2500\u2500 base.py <- Abstract class for training model \u2502 \u2502 \u2514\u2500\u2500 tester.py <- Class implementing routines to train the model \u2502 \u2502 \u2502 \u251c\u2500\u2500 utils <- utility classes and function \u2502 \u2502 \u251c\u2500\u2500\u2500 io <- Module for input/output operations \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500 read.py <- Read from disk functions utility, like Read configuration file, ... etc \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500 write.py <- write to disk functions utility, liek write to csv file, ... etc \u2502 \u2514\u2500\u2500 tox.ini <- tox file with settings for running tox; see tox.readthedocs.io","title":"Project layout"}]}